model:
  target: "prior.diffusion_prior.DiffusionPrior"
  params:
    parameterization: "x0"
    scale_embeddings: true
    optimizer_params:
        lr: 2e-4
        betas: [0.9, 0.999]
        eps: 1e-08
        weight_decay: 0.01
    language_model_config:
      target: "prior.adapter.OpenClipAdapter"
      params:
        path: "hf-hub:laion/CLIP-ViT-B-32-laion2B-s34B-b79K"
    noise_scheduler_config:
      target: "prior.gaussian_diffusion.NoiseScheduler"
      params:
        beta_schedule: "cosine"
        timesteps: 1000
        loss_type: "l2"
    prior_transformer_config:
      target: "prior.prior_transformer.PriorTransformer"
      params:
        ctx_len: 77
        emb_dim: 512
        num_layers: 8
        num_heads: 8
        final_ln: true
        clip_dim: 512
        dropout: 0.00
trainer:
  train_data_urls: "/home/nousr/data/image/laion_coyo_local/{00000..00098}.tar"
  val_data_urls: "/home/nousr/data/image/laion_coyo_local/00099.tar"
  epoch_length: null
  batch_size: 256
  wandb_project: "prior-testing"
  precision: "bf16-mixed"
  max_epochs: 1
  gradient_clip_val: 0.5
  accumulate_grad_batches: 1
  limit_val_batches: 1
  val_check_interval: 512
  enable_checkpointing: false